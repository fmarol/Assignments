{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "name": "pyspark",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "2.7.14",
      "name": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython2",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "ST446_Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmarol/Assignments/blob/master/ST446_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEL0qha9Le-O",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLs-wtfFLe-Z",
        "colab_type": "text"
      },
      "source": [
        "## Assignment 1\n",
        "\n",
        "We start by setting up the bucket and cluster. For part 1 & 2 we need to use the author-large.txt file, so we download this from the url link and place it in our bucket. \n",
        "\n",
        "The steps taken to do this are as follows:\n",
        "\n",
        "\n",
        "The code ran to do this can be seen in Image 1 and 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNT51NNrLe-e",
        "colab_type": "text"
      },
      "source": [
        "### Part 1\n",
        "First we \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi1LJI1XLe-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_from_file = sc.\\\n",
        "    textFile(\"gs://dora-bucket/author-large.txt\", 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WMY8fASgLe-4",
        "colab_type": "code",
        "colab": {},
        "outputId": "85538de2-f8c9-43fa-81b7-18a42b8be684"
      },
      "source": [
        "data_from_file.take(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'Jurgen Annevelink\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n",
              " u'Rafiul Ahad\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n",
              " u'Amelia Carlson\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n",
              " u'Daniel H. Fishman\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995',\n",
              " u'Michael L. Heytens\\tModern Database Systems\\tObject SQL - A Language for the Design and Implementation of Object Databases.\\t1995']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rIkP_zxLe_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhk9ID0JLe_n",
        "colab_type": "code",
        "colab": {},
        "outputId": "3b525ee7-e5d4-430e-e0b5-6ceee1d43104"
      },
      "source": [
        "import numpy as np\n",
        "data_from_file_conv = data_from_file.map(lambda row: np.array(row.strip().split(\"\\t\")))\n",
        "data_from_file_conv.take(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([u'Jurgen Annevelink', u'Modern Database Systems',\n",
              "        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "        u'1995'], dtype='<U78'),\n",
              " array([u'Rafiul Ahad', u'Modern Database Systems',\n",
              "        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "        u'1995'], dtype='<U78'),\n",
              " array([u'Amelia Carlson', u'Modern Database Systems',\n",
              "        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "        u'1995'], dtype='<U78'),\n",
              " array([u'Daniel H. Fishman', u'Modern Database Systems',\n",
              "        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "        u'1995'], dtype='<U78'),\n",
              " array([u'Michael L. Heytens', u'Modern Database Systems',\n",
              "        u'Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "        u'1995'], dtype='<U78')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va0c5BkjLe_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DczWQNbyLfAL",
        "colab_type": "code",
        "colab": {},
        "outputId": "e78d3ee3-6e74-4d51-d299-d67f53e4f87d"
      },
      "source": [
        "#take only the Name and Title\n",
        "book_authors = data_from_file_conv.map(lambda row: (row[2], row[0]))\n",
        "#join the dataset on itself along the Title so that we have all possible combinations of pairs of authors for each book\n",
        "book_authors_join = book_authors.join(book_authors).filter(lambda row: row[1][0]<row[1][1])\n",
        "book_authors_join.take(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(u'Impact of the Processing Methods on the Performance of the X-ray Film Screen Combinations.',\n",
              "  (u'Cao Hou-de', u'Wang Yong-ming')),\n",
              " (u'Fusing multiple systems into a compact lattice index for chinese spoken term detection.',\n",
              "  (u'Peng Yu', u'Sha Meng')),\n",
              " (u'Fusing multiple systems into a compact lattice index for chinese spoken term detection.',\n",
              "  (u'Jia Liu', u'Sha Meng')),\n",
              " (u'Fusing multiple systems into a compact lattice index for chinese spoken term detection.',\n",
              "  (u'Jia Liu', u'Peng Yu')),\n",
              " (u'Fusing multiple systems into a compact lattice index for chinese spoken term detection.',\n",
              "  (u'Frank Seide', u'Sha Meng'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmnOMYTQLfAf",
        "colab_type": "code",
        "colab": {},
        "outputId": "ccfe60ba-7401-4415-8070-303e4c7dea94"
      },
      "source": [
        "#Check if the rows in the tables are unique - do we have any repeats? If so then we want to avoid counting pair-title values multiple times\n",
        "book_authors_join.map(lambda row: ((row[0], row[1]), 1)).reduceByKey(lambda x, y: x+y).filter(lambda row: row[1] != 1).take(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((u'Introduction.', (u'James Ohene-Djan', u'Robert Logcher')), 2),\n",
              " ((u'Adaptive Video on Demand.', (u'Amir Herzberg', u'Sudhanshu Aggarwal')),\n",
              "  4),\n",
              " ((u'Minitrack Introduction.', (u'Jrg M. Haake', u'Judith Gebauer')), 2),\n",
              " ((u'Minitrack Introduction.', (u'Robert O. Briggs', u'Samuli Pekkola')), 2),\n",
              " ((u'Minitrack Introduction.',\n",
              "   (u'Christopher P. Holland', u'Mark N. Frolick')),\n",
              "  2),\n",
              " ((u'A Semantic Data Grid for Satellite Mission Quality Analysis.',\n",
              "   (u'Manuel Snchez-Gestido', u'scar Corcho')),\n",
              "  4),\n",
              " ((u'3.', (u'Gershon Elber', u'Yuefei Zhu')), 2),\n",
              " ((u'Minitrack Introduction.', (u'Pirkko Walden', u'Scott McCoy')), 4),\n",
              " ((u'BLOG: Probabilistic Models with Unknown Objects.',\n",
              "   (u'Andrey Kolobov', u'Brian Milch')),\n",
              "  4),\n",
              " ((u'Minitrack Introduction.', (u'Kenneth J. Trimmer', u'Marios Koufaris')),\n",
              "  2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B38umPsoLfAw",
        "colab_type": "code",
        "colab": {},
        "outputId": "b2045422-1a10-4482-a094-5f0769001631"
      },
      "source": [
        "#it appears that some pair-title combinations appear more than once therefore we group by these combinations before mapping the pairs to values of 1\n",
        "count = book_authors_join.map(lambda row: ((row[0], row[1]), 1)).groupByKey().mapValues(list).map(lambda row: (row[0][1], 1))\n",
        "count.take(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((u'Don DeSota', u'Sameh Sharkawi'), 1),\n",
              " ((u'Xiao-Yuan Jing', u'Yong-Chuan Zhang'), 1),\n",
              " ((u'Guy-Ren Perrin', u'Wolfgang Karl'), 1),\n",
              " ((u'J. W. Park', u'Y. S. Moon'), 1),\n",
              " ((u'Shuichi Sakai', u'Toshitsugu Yuba'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdVau2iqLfBB",
        "colab_type": "code",
        "colab": {},
        "outputId": "14d26310-7ca1-47a8-b621-baa392f622c5"
      },
      "source": [
        "#finally we reduce by author pairs, summing up the mapped values and then sorting the sums in descending order to give the top 10 author pairs\n",
        "count.reduceByKey(lambda x, y: x+y).sortBy(lambda row: row[1], ascending = False).take(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((u'Irith Pomeranz', u'Sudhakar M. Reddy'), 246),\n",
              " ((u'Amr El Abbadi', u'Divyakant Agrawal'), 161),\n",
              " ((u'Makoto Takizawa', u'Tomoya Enokido'), 137),\n",
              " ((u'Didier Dubois', u'Henri Prade'), 122),\n",
              " ((u'Elizabeth Chang', u'Tharam S. Dillon'), 115),\n",
              " ((u'Mary Jane Irwin', u'Narayanan Vijaykrishnan'), 107),\n",
              " ((u'Mahmut T. Kandemir', u'Mary Jane Irwin'), 100),\n",
              " ((u'Chun Chen', u'Jiajun Bu'), 99),\n",
              " ((u'Shojiro Nishio', u'Takahiro Hara'), 96),\n",
              " ((u'Filip De Turck', u'Piet Demeester'), 90)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VB9SBECLfBW",
        "colab_type": "text"
      },
      "source": [
        "Part 2\n",
        "create table in pySpark with schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHQ4QagiLfBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'gs://dora-bucket/author-large.txt'\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"author\", StringType(), True),    \n",
        "    StructField(\"journal\", StringType(), True),\n",
        "    StructField(\"title\", StringType(), True),\n",
        "    StructField(\"year\", LongType(), True)\n",
        "])\n",
        "\n",
        "author_large = spark.read.csv(filename, \n",
        "                    header='false', schema=schema, sep='\\t')\n",
        "author_large.createOrReplaceTempView(\"author_large\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVONL6DyLfBq",
        "colab_type": "code",
        "colab": {},
        "outputId": "e5eedd15-af1b-4580-9d75-e0aa2959683b"
      },
      "source": [
        "spark.sql(\"\"\"with all_combos as (select CONCAT(a2.author, ', ', a1.author) author_pair, a1.title\n",
        "        from author_large a1 join author_large a2 on a1.title=a2.title where a1.author>a2.author)\n",
        "        select author_pair, count(distinct title) count from all_combos group by author_pair order by count desc\"\"\").show(10, truncate = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------+-----+\n",
            "|author_pair                             |count|\n",
            "+----------------------------------------+-----+\n",
            "|Irith Pomeranz, Sudhakar M. Reddy       |246  |\n",
            "|Amr El Abbadi, Divyakant Agrawal        |161  |\n",
            "|Makoto Takizawa, Tomoya Enokido         |137  |\n",
            "|Didier Dubois, Henri Prade              |122  |\n",
            "|Elizabeth Chang, Tharam S. Dillon       |115  |\n",
            "|Mary Jane Irwin, Narayanan Vijaykrishnan|107  |\n",
            "|Mahmut T. Kandemir, Mary Jane Irwin     |100  |\n",
            "|Chun Chen, Jiajun Bu                    |99   |\n",
            "|Shojiro Nishio, Takahiro Hara           |96   |\n",
            "|Filip De Turck, Piet Demeester          |90   |\n",
            "+----------------------------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAtu7sHtLfB7",
        "colab_type": "text"
      },
      "source": [
        "Part 3\n",
        "\n",
        "Need to transform JSON into a dataframe using Hive\n",
        "Lets look at the first line of the JSON file\n",
        "Download JAR file\n",
        "\n",
        "Code for download\n",
        "SSH:\n",
        "gsutil cp gs://dora-bucket/hive-json-serde.jar hive-json-serde.jar\n",
        "gsutil cp gs://dora-bucket/yelp_academic_dataset_user.json yelp_academic_dataset_user.json\n",
        "\n",
        "\n",
        " \"user_id\": \"myql3o3x22_ygECb8gVo7A\",\n",
        "  \"name\": \"Vivian\",\n",
        "  \"review_count\": 80,\n",
        "  \"yelping_since\": \"2009-06-27\",\n",
        "  \"friends\" : [...],\n",
        "  \"useful\": 117,\n",
        "  \"funny\": 28,\n",
        "  \"cool\": 104,\n",
        "  \"fans\": 34,\n",
        "  \"elite\": [\n",
        "    \"None\"\n",
        "  ],\n",
        "  \"average_stars\": 4.29,\n",
        "  \"compliment_hot\": 64,\n",
        "  \"compliment_more\": 4,\n",
        "  \"compliment_profile\": 5,\n",
        "  \"compliment_cute\": 11,\n",
        "  \"compliment_list\": 1,\n",
        "  \"compliment_note\": 97,\n",
        "  \"compliment_plain\": 129,\n",
        "  \"compliment_cool\": 144,\n",
        "  \"compliment_funny\": 144,\n",
        "  \"compliment_writer\": 17,\n",
        "  \"compliment_photos\": 24,\n",
        "  \"type\": \"user\"\n",
        "\n",
        "CREATE EXTERNAL TABLE IF NOT EXISTS my_table (\n",
        " user_id STRING,\n",
        "  name STRING,\n",
        "  review_count INT,\n",
        "  yelping_since STRING,\n",
        "  friends ARRAY<STRING>,\n",
        "  useful INT,\n",
        "  funny INT,\n",
        "  cool INT,\n",
        "  fans INT,\n",
        "  elite ARRAY<STRING>,\n",
        "  verage_stars FLOAT,\n",
        "  compliment_hot INT,\n",
        "  compliment_more INT,\n",
        "  compliment_profile INT,\n",
        "  compliment_cute INT,\n",
        "  compliment_list INT,\n",
        "  compliment_note INT,\n",
        "  compliment_plain INT,\n",
        "  compliment_cool INT,\n",
        "  compliment_funny INT,\n",
        "  compliment_writer INT,\n",
        "  compliment_photos INT,\n",
        "  type STRING ) \n",
        "ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.JsonSerde' \n",
        "LOCATION 'path/to/my_table/';\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiHnO0qdLfCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}